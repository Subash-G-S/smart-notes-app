# ğŸ§  Smart Document Search (RAG App with OpenAI + Pinecone)

This project lets you **upload documents (PDF, TXT, or HTML)**, automatically **index them in Pinecone** using **OpenAI embeddings**, and then **ask natural language questions** about them â€” all powered by **Retrieval-Augmented Generation (RAG)**.

---

## ğŸš€ Features

- ğŸ“„ Upload PDF, TXT, or HTML documents  
- âœ‚ï¸ Automatically chunk and process large files  
- ğŸ§  Convert text into **OpenAI embeddings** (`text-embedding-3-small`)  
- ğŸ—„ï¸ Store and query embeddings using **Pinecone Vector DB**  
- ğŸ” Ask AI-powered questions across all your documents  
- ğŸ—‘ï¸ Manage (list or delete) uploaded files easily  
- âš™ï¸ RESTful Express backend, ready for any frontend integration  

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|------------|-------------|
| **Backend** | Node.js + Express |
| **AI Models** | OpenAI `text-embedding-3-small`, `gpt-4o-mini` |
| **Vector Database** | Pinecone |
| **File Handling** | express-fileupload, pdf-parse |
| **Language** | JavaScript (ES Modules) |
| **Environment** | dotenv |

---

## ğŸ“‚ Folder Structure

```
.
â”œâ”€â”€ server.js             # Main backend file
â”œâ”€â”€ .env                  # Environment variables
â”œâ”€â”€ uploads/              # Uploaded files (auto-created)
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/smart-document-search.git
cd smart-document-search
```

### 2ï¸âƒ£ Install Dependencies
```bash
npm install
```

### 3ï¸âƒ£ Create a `.env` File
In your project root, create a file named `.env` with:
```
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
```
> ğŸ§© Get your keys from:
> - OpenAI: [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)  
> - Pinecone: [https://app.pinecone.io](https://app.pinecone.io)

---

### 4ï¸âƒ£ Create Your Pinecone Index

Run this **once** to create your index:
```bash
node createIndex.mjs
```

Use:
- **Index name:** `notes-search`  
- **Dimension:** `1536` (for `text-embedding-3-small`)  
- **Metric:** `cosine`

Wait 1â€“2 minutes for the index to show â€œReadyâ€ in Pinecone.

---

### 5ï¸âƒ£ Start the Server
```bash
node server.js
```

âœ… Your backend will start on:
```
http://localhost:5000
```

---

## ğŸ”— API Endpoints

| Endpoint | Method | Description |
|-----------|--------|-------------|
| `/upload` | **POST** | Upload a document. Extracts text, chunks it, generates embeddings, and stores in Pinecone. |
| `/search` | **POST** | Search documents with a question â†’ Retrieves context and generates answer. |
| `/files` | **GET** | List uploaded files. |
| `/delete/:filename` | **DELETE** | Delete a file + its namespace. |
| `/check-index` | **GET** | Check Pinecone index stats (debugging). |

---

## ğŸ§  Example Usage

### ğŸ“ Upload
**POST** `/upload`
```
form-data:
  file: example.pdf
```

**Response:**
```json
{
  "success": true,
  "message": "example.pdf uploaded & indexed successfully.",
  "chunks": 42
}
```

---

### ğŸ” Search
**POST** `/search`
```json
{
  "query": "What are the main causes of air pollution?"
}
```

**Response:**
```json
{
  "answer": "Air pollution is mainly caused by emissions from vehicles and industries.",
  "sources": [
    {
      "file": "pollution.pdf",
      "text": "Air pollution is caused by burning fossil fuels..."
    }
  ]
}
```

---

## ğŸ§© How It Works (RAG Flow)

```
1. File Upload â†’ Text Extraction â†’ Chunking
2. Generate Embeddings (OpenAI)
3. Store Embeddings + Metadata in Pinecone
4. User Query â†’ Query Embedding â†’ Pinecone Similarity Search
5. Retrieve Context â†’ GPT Model â†’ Final Answer
```

---

## ğŸ§° Troubleshooting

| Issue | Cause | Fix |
|--------|--------|-----|
| âŒ `Cannot read properties of undefined (reading 'text')` | Some Pinecone vectors missing metadata | Use optional chaining `m.metadata?.text` or re-upload |
| âŒ No records in Pinecone | Index not created or wrong API key | Verify `.env`, create index, and reconnect |
| âš ï¸ Slow upload for large files | Embeddings done sequentially | Implement batch embedding or parallel upload |

---

## ğŸ§¹ Maintenance

Clear a namespace:
```js
await index.namespace("yourfile.txt").deleteAll();
```

List namespaces:
```js
const ns = await index.listNamespaces();
console.log(ns.namespaces);
```

---

## ğŸ“¸ Example Console Output
```
ğŸ“‚ Uploaded: document.txt
ğŸ”¹ Embedding for chunk 0: [0.001, -0.002, 0.123, ...]
ğŸ Vectors upserted successfully!
ğŸ” Query results: Found 3 matching chunks.
âœ… GPT Answer generated successfully.
```

---

## ğŸ’¡ Future Enhancements
- â±ï¸ Batch embeddings for faster uploads  
- ğŸ” Add metadata-based filtering  
- ğŸŒ Build a React/Next.js UI for frontend search  
- ğŸ’¾ Add MongoDB/SQLite for tracking file metadata  

---

## ğŸ§‘â€ğŸ’» Author
**G S Subash Chandra Bose**  
ğŸ’¬ *â€œBuilding AI that actually understands your data.â€*  
ğŸ“§ [your-email@example.com]  

---

## ğŸªª License
This project is licensed under the **MIT License** â€” free to use and modify.

---

â­ **If you like this project, consider giving it a star on GitHub!**
